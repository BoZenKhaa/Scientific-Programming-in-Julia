<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Lecture · Scientific Programming in Julia</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://JuliaTeachingCTU.github.io/Scientific-Programming-in-Julia/lecture_13/lecture/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.svg" alt="Scientific Programming in Julia logo"/><img class="docs-dark-only" src="../../assets/logo-dark.svg" alt="Scientific Programming in Julia logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Scientific Programming in Julia</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../installation/">Installation</a></li><li><a class="tocitem" href="../../projects/">Projects</a></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">1: Introduction</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_01/motivation/">Motivation</a></li><li><a class="tocitem" href="../../lecture_01/basics/">Basics</a></li><li><a class="tocitem" href="../../lecture_01/demo/">Examples</a></li><li><a class="tocitem" href="../../lecture_01/outline/">Outline</a></li><li><a class="tocitem" href="../../lecture_01/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_01/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">2: The power of Type System &amp; multiple dispatch</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_02/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_02/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_02/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">3: Design patterns</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_03/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_03/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_03/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-7" type="checkbox"/><label class="tocitem" for="menuitem-7"><span class="docs-label">4: Packages development, Unit Tests &amp; CI</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_04/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_04/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_04/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-8" type="checkbox"/><label class="tocitem" for="menuitem-8"><span class="docs-label">5: Benchmarking, profiling, and performance gotchas</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_05/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_05/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_05/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-9" type="checkbox"/><label class="tocitem" for="menuitem-9"><span class="docs-label">6: Language introspection</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_06/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_06/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_06/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-10" type="checkbox"/><label class="tocitem" for="menuitem-10"><span class="docs-label">7: Macros</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_07/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_07/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_07/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-11" type="checkbox"/><label class="tocitem" for="menuitem-11"><span class="docs-label">8: Introduction to automatic differentiation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_08/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_08/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_08/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-12" type="checkbox"/><label class="tocitem" for="menuitem-12"><span class="docs-label">9: Manipulating intermediate representation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_09/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_09/lab/">Lab</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-13" type="checkbox"/><label class="tocitem" for="menuitem-13"><span class="docs-label">10: Different levels of parallel programming</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_10/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_10/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_10/hw/">Homework</a></li></ul></li><li><span class="tocitem">11: Julia for GPU programming</span></li><li><input class="collapse-toggle" id="menuitem-15" type="checkbox"/><label class="tocitem" for="menuitem-15"><span class="docs-label">12: Uncertainty propagation in ODE</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_12/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_12/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_12/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-16" type="checkbox" checked/><label class="tocitem" for="menuitem-16"><span class="docs-label">13: Learning ODE from data</span><i class="docs-chevron"></i></label><ul class="collapsed"><li class="is-active"><a class="tocitem" href>Lecture</a><ul class="internal"><li><a class="tocitem" href="#Fitting-ODE-solution-to-data"><span>Fitting ODE solution to data</span></a></li><li><a class="tocitem" href="#Extending-the-ODE"><span>Extending the ODE</span></a></li><li class="toplevel"><a class="tocitem" href="#Neural-Networks-in-Julia"><span>Neural Networks in Julia</span></a></li><li><a class="tocitem" href="#Multi-layer-perceptron"><span>Multi-layer perceptron</span></a></li><li><a class="tocitem" href="#FastChain"><span>FastChain</span></a></li><li class="toplevel"><a class="tocitem" href="#Neural-Networks-in-ODEs:"><span>Neural Networks in ODEs:</span></a></li><li><a class="tocitem" href="#Neural-Lotka-Volterra"><span>Neural Lotka-Volterra</span></a></li><li><a class="tocitem" href="#Physics-informed-Neural-Network"><span>Physics-informed Neural Network</span></a></li><li class="toplevel"><a class="tocitem" href="#Data-assimilation-in-uncertain-ODEs"><span>Data assimilation in uncertain ODEs</span></a></li><li><a class="tocitem" href="#Bayesian-filtering"><span>Bayesian filtering</span></a></li></ul></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">13: Learning ODE from data</a></li><li class="is-active"><a href>Lecture</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Lecture</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaTeachingCTU/Scientific-Programming-in-Julia/blob/master/docs/src/lecture_13/lecture.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Data-driven-Ordinary-Differential-Equations"><a class="docs-heading-anchor" href="#Data-driven-Ordinary-Differential-Equations">Data-driven Ordinary Differential Equations</a><a id="Data-driven-Ordinary-Differential-Equations-1"></a><a class="docs-heading-anchor-permalink" href="#Data-driven-Ordinary-Differential-Equations" title="Permalink"></a></h1><p>We have looked into the uncertainty propagation trough an ODE in previous lecture. The uncertainty may stem from:</p><ul><li>unknown boundary consitions (e.g. initial conditions)</li><li>unknown parameters, </li><li>missing terms (hidden dynamics) of ODE</li></ul><p>The uncertainty in the solution can be reduced when data are available. This can be either in incremental or batch form:</p><ul><li>batch form: we have a set of data </li><li>incremental: common e.g. in temporal evolution, when the data are measured on the fly and systems cna change in time</li></ul><h2 id="Fitting-ODE-solution-to-data"><a class="docs-heading-anchor" href="#Fitting-ODE-solution-to-data">Fitting ODE solution to data</a><a id="Fitting-ODE-solution-to-data-1"></a><a class="docs-heading-anchor-permalink" href="#Fitting-ODE-solution-to-data" title="Permalink"></a></h2><p>Since ODE solver is a function like any other, it is possible to use general-purpose optimizers to optimize parameters of the ODE to match the output.</p><pre><code class="language-julia hljs">using Optim

function loss(θin,prob::ODEProblem,Y)
    prob.θ.=θin
    t,Xn=solve(prob,RK2(0.2))
    sum((Y.-Xn).^2)
end
θopt = copy(θ)
O=Optim.optimize(θ-&gt;loss(θ,prob,X),θopt)</code></pre><ul><li>show various optimizers?</li><li>gradient optimizers?</li></ul><h2 id="Extending-the-ODE"><a class="docs-heading-anchor" href="#Extending-the-ODE">Extending the ODE</a><a id="Extending-the-ODE-1"></a><a class="docs-heading-anchor-permalink" href="#Extending-the-ODE" title="Permalink"></a></h2><p>The previous approach will work only if the data were generated by the exact ODE. If the structure of ODE is different, e.g. soem terms are missing, we can never find an exact fit.</p><p class="math-container">\[\begin{align}
\dot{x}&amp;=\alpha x-\beta xy + {\color{red} \omega y},\\\
dot{y}&amp;=-\delta y+\gamma xy, 
\end{align}\]</p><p>We could &quot;guess&quot; what is the missing term or add a black box (neural network). The whole problem will become finding parameters <span>$\theta = [\theta_{ODE},\theta_{NN}]$</span>. </p><p class="math-container">\[\frac{d\mathbf{x}}{dt}=f(\mathbf{x},\theta) + NN(\mathbf{x},\theta)\]</p><p>In the limiting case, we may learn only the network:</p><p class="math-container">\[\frac{d\mathbf{x}}{dt}=f(\mathbf{x},\theta) + NN(\mathbf{x},\theta)\]</p><p>known as the &quot;Neural ODE&quot; [citation needed].</p><h1 id="Neural-Networks-in-Julia"><a class="docs-heading-anchor" href="#Neural-Networks-in-Julia">Neural Networks in Julia</a><a id="Neural-Networks-in-Julia-1"></a><a class="docs-heading-anchor-permalink" href="#Neural-Networks-in-Julia" title="Permalink"></a></h1><p>Many possible packages implementing Neural Networks (Flux, Knets, MXnets, tensorFlow) etc. By far the most used package is the <code>Flux.jl</code></p><h2 id="Multi-layer-perceptron"><a class="docs-heading-anchor" href="#Multi-layer-perceptron">Multi-layer perceptron</a><a id="Multi-layer-perceptron-1"></a><a class="docs-heading-anchor-permalink" href="#Multi-layer-perceptron" title="Permalink"></a></h2><p>A simple feed-forward neural network (multi-layer-perceptron) </p><p class="math-container">\[y=σ(W_n σ(W_{n-1}\ldots σ(W_{1}x+b_1)\ldots )+b_n)\]</p><p>is implemented as a <code>Chain</code> of layers:</p><pre><code class="language-julia hljs">struct Chain{T}
  layers::T
  Chain(xs...) = new{typeof(xs)}(xs)
  #...
end</code></pre><p>The layers again follow the maths, e.g. <code>Dense</code></p><pre><code class="language-julia hljs">struct Dense{F, M&lt;:AbstractMatrix, B}
  weight::M
  bias::B
  σ::F
end

Dense(W, b) = Dense(W, b, identity)

function (a::Dense)(x::AbstractArray)
  W, b, σ = a.weight, a.bias, a.σ
  return σ.(W*x .+ b)
end</code></pre><p>While it is straightforward compose a MLP:</p><pre><code class="language-julia hljs">nx = 2
nn = Chain(Dense(rand(nx,nx),rand(nx)))</code></pre><p>Now, we would like to optimize its parameters. It would be cumbersume to write into them.</p><h3 id="Functors.jl"><a class="docs-heading-anchor" href="#Functors.jl">Functors.jl</a><a id="Functors.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Functors.jl" title="Permalink"></a></h3><p>In Flux, the standard mechanism is to compose an <code>IdSet</code> with a list of all parameters and operate on that list. </p><pre><code class="language-julia hljs">ps = params(nn)
ps[1]</code></pre><p>Now all operations (even gradients) can be defined on the list. The gradients are stored in an `<span>$IdDict$</span> with pointer to the parameter as the key:</p><pre><code class="nohighlight hljs">gs=gradient(nn,ps)
gs[ps[1]]</code></pre><p>This approach has benefits and drawbacks:</p><ul><li>it allows to write a very general code easily, </li><li>removing parameter from optimization can be done by removing it from the parameter list</li><li>it introduces and overhead<ul><li>may be negligible for large models (hundrets of hidden neurons) that are dominated by matrix manipulation.</li><li>becomes significant for low dimensional models (ODEs)</li></ul></li></ul><h2 id="FastChain"><a class="docs-heading-anchor" href="#FastChain">FastChain</a><a id="FastChain-1"></a><a class="docs-heading-anchor-permalink" href="#FastChain" title="Permalink"></a></h2><p>As an alternative, package <code>DiffEqFlux.jl</code> introduces a different concept of the Chain and Layers, called FastChain and FastLayers.</p><pre><code class="language-julia hljs">abstract type FastLayer &lt;: Function end</code></pre><p>with interface </p><pre><code class="language-julia hljs">paramlength(f) = 0
initial_params(f) = Float32[]</code></pre><p>that need to be specialized for layers.</p><p>The layer that we will be working with is the <code>FastDense</code>:</p><pre><code class="language-julia hljs">struct FastDense{F,F2} &lt;: FastLayer
  out::Int
  in::Int
  σ::F
  initial_params::F2
  bias::Bool
  # function FastDense(...
end</code></pre><p>It does not store its parameters but operates on an external parameter vector:</p><pre><code class="language-julia hljs">(f::FastDense)(x,p) = ((f.bias == true ) ? (f.σ.(reshape(p[1:(f.out*f.in)],f.out,f.in)*x .+ p[(f.out*f.in+1):end])) : (f.σ.(reshape(p[1:(f.out*f.in)],f.out,f.in)*x)))</code></pre><p>The same behavior is replicated in FastChain:</p><pre><code class="language-julia hljs">struct FastChain{T&lt;:Tuple} &lt;: FastLayer
  layers::T
  # function FastChain(xs...)...
end</code></pre><p>Since it is a Layer, it implemnets interfaces:</p><pre><code class="language-julia hljs">paramlength(c::FastChain) = sum(paramlength(x) for x in c.layers)
initial_params(c::FastChain) = vcat(initial_params.(c.layers)...)</code></pre><p>and the functor:</p><pre><code class="language-julia hljs">(c::FastChain)(x,p) = applychain(c.layers, x, p)
applychain(::Tuple{}, x, p) = x
applychain(fs::Tuple, x, p) = applychain(Base.tail(fs), first(fs)(x,p[1:paramlength(first(fs))]), p[(paramlength(first(fs))+1):end])</code></pre><p>The same 2x2 network can be implemented as:</p><pre><code class="language-julia hljs">nn=FastDense(2,2)
p = initial_params(nn)
nn([1,2],p)</code></pre><h1 id="Neural-Networks-in-ODEs:"><a class="docs-heading-anchor" href="#Neural-Networks-in-ODEs:">Neural Networks in ODEs:</a><a id="Neural-Networks-in-ODEs:-1"></a><a class="docs-heading-anchor-permalink" href="#Neural-Networks-in-ODEs:" title="Permalink"></a></h1><p>Neural networks are universal approximators. They can approaximate:</p><ul><li>the ODE, yielding NeuralODE, solved by an arbitrary solver</li><li>the solution of an ODE - replacing the solver. Physics informed neural network (PINN)</li></ul><h2 id="Neural-Lotka-Volterra"><a class="docs-heading-anchor" href="#Neural-Lotka-Volterra">Neural Lotka-Volterra</a><a id="Neural-Lotka-Volterra-1"></a><a class="docs-heading-anchor-permalink" href="#Neural-Lotka-Volterra" title="Permalink"></a></h2><p>Consider an extension of the LV ODE by a MLP:</p><pre><code class="language-julia hljs">function fnn(x,θ,nn,p)
  α,β,γ,δ = θ
  x1,x2=x
   dx1 = α*x1 - β*x1*x2
   dx2 = δ*x1*x2 - γ*x2
  [dx1,dx2]+nn(x,p)
end</code></pre><ul><li>run through solver (RK2)</li><li>optimize, show ambiguity</li></ul><h2 id="Physics-informed-Neural-Network"><a class="docs-heading-anchor" href="#Physics-informed-Neural-Network">Physics-informed Neural Network</a><a id="Physics-informed-Neural-Network-1"></a><a class="docs-heading-anchor-permalink" href="#Physics-informed-Neural-Network" title="Permalink"></a></h2><p>The idea is rather simple:</p><ul><li>neural network can approximate any function - why not solution to an ODE</li><li>we need to define the objective. </li></ul><p>Architecture of NN?</p><p>A solution of ODE should satisfy:</p><ul><li>boundary (initial) conditions </li><li>the ODE at every point on the domain</li></ul><p>While this would be dificult to satisfy in general, it is relatively simple to define on a grid. For the Lotka-Voltera problem, we have two conditions:</p><p class="math-container">\[\begin{align}
x(t)&amp;=x0 &amp;&amp; \text{for }t=0,\\
dx(t)&amp;=f(x_t), &amp;&amp; \text{for } t = \Delta{}t, 2\Delta{}t, \ldots , N\Delta{}t 
\end{align}\]</p><p>This can be summarized in a loss function:</p><p class="math-container">\[\mathcal{L}=||nn(0)-x0)|| + \frac{1}{N}\sum_{i=1}^N||f(x_i)-\nabla_x nn(x_i) ||\]</p><p>This straightforward approach was proposed relatively recently (2019).</p><ul><li>the training is not easy</li><li>need for higher-order derivatives</li><li>numerical issues</li></ul><p>Worked out in the lab.</p><p>Can be combined with Neural ODE.</p><h1 id="Data-assimilation-in-uncertain-ODEs"><a class="docs-heading-anchor" href="#Data-assimilation-in-uncertain-ODEs">Data assimilation in uncertain ODEs</a><a id="Data-assimilation-in-uncertain-ODEs-1"></a><a class="docs-heading-anchor-permalink" href="#Data-assimilation-in-uncertain-ODEs" title="Permalink"></a></h1><p>So far, we have seen optimizations of the ODEs in the form of point estimate. We have seen an almost perfect fit. This may be dangerous when:</p><ul><li>the measurement are uncertain with large possible error</li><li>the number of measurements is insufficient to fit the model.</li></ul><p>Consider the Monte Carlo simulation from the previous lecture:</p><pre><code class="language-julia hljs">K=100
X0 = [x0 .+ 0.1*randn(2) for k=1:K]
θ1 =[[θ0[1]+0.01randn();θ0[2:end]] for k=1:K]
Xens=[X=solve(f,X0[i],θ1[i],dt,N) for i=1:K]</code></pre><p><img src="../LV_MC_param.svg" alt/></p><p>We have observed data for every 100th sample with standard deviation 0.2.</p><p><img src="../LV_MC_param_data.svg" alt/></p><p>Point estimate is the trajectory with the thick color.</p><ul><li>it is the one with minimum error</li><li>is it really the solution?</li></ul><p>Lets, select all trajectories withing a selected tolerance:</p><p><img src="../LV_MC_param_assim.svg" alt/></p><h2 id="Bayesian-filtering"><a class="docs-heading-anchor" href="#Bayesian-filtering">Bayesian filtering</a><a id="Bayesian-filtering-1"></a><a class="docs-heading-anchor-permalink" href="#Bayesian-filtering" title="Permalink"></a></h2><p>When the data are collected sequentially, the process of reduction of the uncertainty is repeated with every new measurement. The procedure is an iteration of two steps:</p><ol><li>prediction - use ODE with uncertainty propagation to the next step,</li><li>correction - use the acquired measurement to reduce the uncertainty</li></ol><p>How exactly are these steps implemented depends on the assumptions made on the type of model uncertainty (initial conditions, parameters, noise) and the measurment uncertainty (noise).</p><p>We have done propagation of the Gaussian uncertainty through an ODE (GaussNum, Cubature rules). We will complement it by the correcton step here. </p><p>Assumption of the Gaussian uncertainty in the ODE as well as the noise is one of the easiest to solve, due to nice properties of the Gaussian distribution. Specifically, joint distribution of a marginal and conditional Gaussian distribution is a Gaussian distribution:</p><p class="math-container">\[\begin{align}
p(\mathbf{x},\mathbf{y})&amp;=\mathcal{N}\left(\begin{bmatrix}\mu_{x}\\
\mu_{y}
\end{bmatrix},\begin{bmatrix}\Sigma_{xx} &amp; \Sigma_{xy}\\
\Sigma_{yx} &amp; \Sigma_{yy}
\end{bmatrix}\right)\\p(\mathbf{y})&amp;=\mathcal{N}\left(\mu_{y},\Sigma_{yy}\right)\\p(\mathbf{x}|\mathbf{y})&amp;=\mathcal{N}(\mu_{x}+\Sigma_{xy}\Sigma_{yy}^{-1}(\mathbf{y}-\mu_{y}),\Sigma_{xx}-\Sigma_{xy}\Sigma_{yy}^{-1}\Sigma_{yx})
\end{align}\]</p><p>We have uncertainty in all our unknowns <span>$p(\mathbf{x})$</span> in the form of quadrature points. We assume that the probability of observation of <span>$p(\mathbf{y}|\mathbf{x})$</span> has mean given by <span>$x$</span> and variance <span>$\sigma_y$</span>. Hence, the means can be obtained by empirical samples of the cubature points <span>$X_p$</span> and measurements corresponding to cubature points.</p><p class="math-container">\[\mu_{x}=\overline{X_{p}}, \mu_{y}=\overline{Y_{p}},\]</p><p>e.g. if the measurements are only the <span>$x$</span> (prey variable) the <span>$Y_p = X_{1,p}$</span>.</p><p>The covariance matrices can be obtained by empirical samples:</p><p class="math-container">\[\begin{align}
\Sigma_{xx}&amp;=\frac{1}{2d}\sum_{j=1}^{2d}(x{}_{i}-\mu_{x})^{T}(x_{i}-\mu_{x}),\\\Sigma_{yx}&amp;=\frac{1}{2d}\sum_{j=1}^{2d}(y{}_{i}-\mu_{y})^{T}(x_{i}-\mu_{x}),\\\Sigma_{yy}&amp;=\frac{1}{2d}\sum_{j=1}^{2d}(y{}_{i}-\mu_{y})^{T}(y_{i}-\mu_{y})+\sigma_{y},
\end{align}\]</p><p>The uncertainty reduction is then application of the conditional distribution using the obtained means and variances. A common trick is to define the Kalman gain:</p><p class="math-container">\[\begin{align}
\mu_{x|y}&amp;=\mu_{x}+K(\mathbf{y}-\mu_{y}),\,\,\,\,K=\Sigma_{xy}\Sigma_{yy}^{-1},\\\Sigma_{x|y}&amp;=\Sigma_{xx}-K\Sigma_{yx},
\end{align}\]</p><p>The full algorithms is then as follows:</p><ol><li>generate sigma points from their mean <span>$\mu_x$</span> and <span>$\Sigma_{xx}$</span></li><li>run propagation of the cubature points <span>$Xp$</span> trough the ODE up to the point of the measuremnets</li><li>compute their mean <span>$\mu_x$</span> and variance <span>$\Sigma_{xx}$</span></li><li>for each cubature point compute the predicted measurement. Compute  mean <span>$\mu_y$</span> and covariance <span>$\Sigma_{yy}$</span></li><li>Compute the reduced uncertainty mean <span>$\mu_{x|y}$</span> and <span>$\Sigma_{x|y}$</span>. These will be used to generate new cubature points in step 1.</li></ol><p>TODO: code in the lab.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../lecture_12/hw/">« Homework</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.10 on <span class="colophon-date" title="Thursday 16 December 2021 13:11">Thursday 16 December 2021</span>. Using Julia version 1.7.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
