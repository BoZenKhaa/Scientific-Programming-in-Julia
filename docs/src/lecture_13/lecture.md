# Data-driven Ordinary Differential Equations

We have looked into the uncertainty propagation through an ODE in the previous lecture. The uncertainty may stem from:
- unknown boundary conditions (e.g. initial conditions)
- unknown parameters (reproduction rates, etc.)
- missing terms (hidden dynamics) of an ODE

The uncertainty in the solution can be reduced when data are available. In this Lecture we will look into:
- estimating parameters of an ODE to match the data, 
- learning unknown ODEs using Neural Networks 
- using neural networks as a solver of Neural networks
- respecting uncertainty in the data 
  - reduction of uncertainty incrementally with the data,
  - Gaussian filter using Cubature rules


## Fitting ODE solution to data

Since the ODE solver is a function like any other, it is possible to use general-purpose optimizers to optimize parameters of the ODE to match the output.
```julia
using Optim

θ2=[0.2,0.2,0.3,0.1]
prob = ODEProblem(f,tspan,[1.0,1.0],θ2)
t,X=solve(prob, RK2(0.2))

function loss(θin,prob::ODEProblem,Y)
    prob.θ.=θin
    t,Xn=solve(prob,RK2(0.2))
    sum((Y.-Xn).^2)
end
θopt = [0.1,0.2,0.3,0.1]
O=Optim.optimize(θ->loss(θ,prob,X),θopt)
Olb=Optim.optimize(θ->loss(θ,prob,X),θopt,LBFGS())
```

- using the power of automatic differentiation (of the numerical solver)
- in the case of ODE, the gradients can be modified to use the information about exact derivatives (adjoints) 

## Extending the ODE

The previous approach will work only if the data were generated by the exact ODE. If the structure of ODE is different, e.g. some terms are missing, we can never find an exact fit.

```math
\begin{align}
\dot{x}&=\alpha x-\beta xy + {\color{red} \omega y},\\\
\dot{y}&=-\delta y+\gamma xy, 
\end{align}
```

For example: with ``\omega = 0.1`` the trajectory becomes:

![](LV_omega.svg)

We could "guess" what is the missing term or add a black box (neural network). The whole problem will become finding parameters ``\theta = [\theta_{ODE},\theta_{NN}]``. 
```math
\frac{d\mathbf{x}}{dt}=f(\mathbf{x},\theta_{ODE}) + NN(\mathbf{x},\theta_{NN})
```
In the limiting case, we may learn only the network:
```math
\frac{d\mathbf{x}}{dt}= NN(\mathbf{x},\theta_{NN})
```
known as the "Neural ODE" (Chen et. al. 2018). We will try to learn neural ODE for the extended systems. We need to look into neural network tools.

# Neural Networks in Julia
Many possible packages implementing Neural Networks (Flux, Knets, MXnets, tensorFlow) etc. By far the most used package is the ```Flux.jl```

## Multi-layer perceptron
A simple feed-forward neural network (multi-layer-perceptron) 
```math
y=σ(W_n σ(W_{n-1}\ldots σ(W_{1}x+b_1)\ldots )+b_n)
```

is implemented as a ```Chain``` of layers:
```julia
struct Chain{T}
  layers::T
  Chain(xs...) = new{typeof(xs)}(xs)
  #...
end
```

The layers again follow the maths, e.g. ```Dense```
```julia
struct Dense{F, M<:AbstractMatrix, B}
  weight::M
  bias::B
  σ::F
end

Dense(W, b) = Dense(W, b, identity)

function (a::Dense)(x::AbstractArray)
  W, b, σ = a.weight, a.bias, a.σ
  return σ.(W*x .+ b)
end
```

Building an MLP is straightforward:
```julia
nx = 2
nn = Chain(Dense(rand(nx,nx),rand(nx)))
```

Now, we would like to optimize its parameters. It would be cumbersume to write into them.


### Functors.jl
In Flux, the standard mechanism is to compose an ```IdSet``` with a list of all parameters and operate on that list. 

```julia
ps = params(nn)
ps[1]
```
Now all operations (even gradients) can be defined on the list. The gradients are stored in an ```IdDict`` with pointer to the parameter as the key:

```julia
gs=gradient(()->sum(nn([1,2])),ps)
gs[ps[1]]
```

This approach has benefits and drawbacks:
- it allows to write a very general code easily, 
- the list of parameters is accessible for modifications:
  - removing parameter from optimization can be done by removing it from the parameter list
  - adding a parameter (e.g. from the ODE) allows composition of NN with other code
- it introduces an overhead
  - may be negligible for large models (hundreds of hidden neurons) that are dominated by matrix manipulation.
  - becomes significant for low dimensional models (ODEs)

## FastChain

As an alternative, package ```DiffEqFlux.jl``` introduces a different concept of the Chain and Layers, called FastChain and FastLayers.

```julia
abstract type FastLayer <: Function end
```
with interface 
```julia
paramlength(f) = 0
initial_params(f) = Float32[]
```
that needs to be specialized for layers.

The layer that we will be working with is the ```FastDense```:

```julia
struct FastDense{F,F2} <: FastLayer
  out::Int
  in::Int
  σ::F
  initial_params::F2
  bias::Bool
  # function FastDense(...
end
```
It does not store its parameters but operates on an external parameter vector:
```julia
(f::FastDense)(x,p) = ((f.bias == true ) 
  ? (f.σ.(reshape(p[1:(f.out*f.in)],f.out,f.in)*x .+ p[(f.out*f.in+1):end])) 
  : (f.σ.(reshape(p[1:(f.out*f.in)],f.out,f.in)*x)))
```

The same behavior is replicated in FastChain:
```julia
struct FastChain{T<:Tuple} <: FastLayer
  layers::T
  # function FastChain(xs...)...
end
```
Since it is a Layer, it implements interfaces:
```julia
paramlength(c::FastChain) = sum(paramlength(x) for x in c.layers)
initial_params(c::FastChain) = vcat(initial_params.(c.layers)...)
```

and the functor:
```julia
(c::FastChain)(x,p) = applychain(c.layers, x, p)
applychain(::Tuple{}, x, p) = x
applychain(fs::Tuple, x, p) = applychain(Base.tail(fs), first(fs)(x,p[1:paramlength(first(fs))]), p[(paramlength(first(fs))+1):end])
```

Other types of layers using StaticArrays are defined for small networks (allocating on the stack).

The same 2x2 network can be implemented as:
```julia
using DiffEqFlux
nn=FastDense(2,2)
p = initial_params(nn)
nn([1,2],p)
```

Effects of code composition in Julia:
- Toolboxes of Neural Networks in Julia are often lightweight
- the tools necessary for their training are not specific to NN (AD: Zygote, Enzyme)
- Combination with ODE is straigthforward

# Neural Networks in ODEs:

With neural networks in place, we can now define an ODE with neural network part.

## Neural Lotka-Volterra
Consider an extension of the LV ODE by a MLP:
```julia
function fnn(x,θ)
    α, β, γ, δ = θ[1:4]
    x₁, x₂ = x

    dx₁ = α*x₁ - β*x₁*x₂ 
    dx₂ = δ*x₁*x₂ - γ*x₂

    [dx₁, dx₂]+nn(x,@view θ[5:end])
end
```
Can be implemented via a closure (closing on nn).

Optimize using the same approach as before:
```julia
θnn = [0.2,0.2,0.3,0.2,0.01*initial_params(nn)...]
probnn = ODEProblem(fnn,tspan,u0,θnn)

θopt = copy(θnn)
O=Optim.optimize(θ->loss(θ,probnn,Xy),θopt,Optim.Options(iterations=10000))
```

The ``Xy`` data were generated with the ω version of the ODE, with parameters ``\theta=[0.2,0.2,0.3,0.2,0.1]``.

Optimization difficulties:
- the number of iteration in Nelder-Mead had to be increased
- LBGFS() optimizer extremely slow

Why?




## Physics-informed Neural Network

The idea is rather simple:
- neural network can approximate any function - why not solution to an ODE: ``\mathbf{x}(t)``
- replaces methods of numerical solution (Euler, RK2)

We need to define:
- Architecture of NN
  - Neural network for the solution of Lotka-Volterra?
- the optimization objective

A solution of ODE should satisfy:
- boundary (initial) conditions 
- the ODE holds at every point of teh solution on its domain

While this would be difficult to satisfy in general, it is relatively simple to define on a grid. For the Lotka-Voltera problem, we have two conditions:
```math
\begin{align}
x(t)&=x0 && \text{for }t=0,\\
dx(t)&=f(x_t), && \text{for } t = \Delta{}t, 2\Delta{}t, \ldots , N\Delta{}t 
\end{align}
```

This can be summarized in a loss function:
```math
\mathcal{L}=||nn(0)-\mathbf{x}_0)|| + \frac{1}{N}\sum_{i=1}^N||f(\mathbf{x}_i)-\nabla_t nn(t_i) ||
```

This straightforward approach was proposed relatively recently (2019).
- the training is not easy
- the need for higher-order derivatives (challenge for sourse-to-source AD)
- numerical issues

Very simple extension for known data:
```math
\begin{align}
\mathcal{L}=&||nn(0)-\mathbf{x}_0)|| + \frac{1}{N}\sum_{i=1}^N||f(\mathbf{x}_i)-\nabla_t nn(t_i) ||\\
            & + \frac{1}{M}\sum_{j=1}^M||y_j - h(nn(t_j))||
\end{align}
```
where ``h()`` is a function transforming ODE solution to observations (e.g. identity, or selection of the relevant observations).

Example will be worked out in the lab.

PINNs can be combined with Neural ODE.

# Data assimilation in uncertain ODEs

So far, we have seen optimizations of the ODEs in the form of point estimate. We have seen an almost perfect fit. This may be dangerous when:
- the measurement are uncertain with large possible error
- the number of measurements is insufficient to fit the model.

Consider the Monte Carlo simulation from the previous lecture extended for unknown parameter:
```julia
K=100
X0 = [x0 .+ 0.1*randn(2) for k=1:K]
θ1 =[[θ0[1]+0.01randn();θ0[2:end]] for k=1:K]
Xens=[X=solve(f,X0[i],θ1[i],dt,N) for i=1:K]
```
![](LV_MC_param.svg)

We have observed data for every 100th sample with standard deviation 0.2.

![](LV_MC_param_data.svg)

Point estimate is the trajectory with the thick color.
- it is the one with minimum error
- is it really the solution?

Lets select all trajectories within a selected tolerance:

![](LV_MC_param_assim.svg)

## Bayesian filtering

When the data are collected sequentially, the process of reduction of the uncertainty is repeated with every new measurement. The procedure is an iteration of two steps:
1. prediction - use ODE with uncertainty propagation to the next step,
2. correction - use the acquired measurement to reduce the uncertainty

Example: weather forecast
- prediction is simulation of the earth atmosphere using PDE
- correction is update of the state of the atmosphere using weather data

In mathematics, it is direct application of the Bayes rule:
```math
\begin{align}
p(\mathbf{x},\mathbf{y})	&=p(\mathbf{y}|\mathbf{x})p(\mathbf{x})=p(\mathbf{x}|\mathbf{y})p(\mathbf{y})\\
p(\mathbf{x}|\mathbf{y})	&=\frac{p(\mathbf{y}|\mathbf{x})p(\mathbf{x})}{p(\mathbf{y})}=\frac{p(\mathbf{y}|\mathbf{x})p(\mathbf{x})}{\int p(\mathbf{y}|\mathbf{x})p(\mathbf{x})d\mathbf{x}}
\end{align}
```

Trade-off between generality and speed
- A implementation of the whole procedure can be done on a general level using types for probability distributions and operations on them.
- How exactly are these steps implemented depends on the assumptions made on the type of model uncertainty (initial conditions, parameters, noise) and the measurement uncertainty (noise).

We have done propagation of the Gaussian uncertainty through an ODE (GaussNum, Cubature rules). We will complement it by the correction step here. 

State augmentation:
- the state variable ``\mathbf{x}`` contains all uncertain information that is required to predict the future
- in the case of uncertain ODE solved above, it would be the ODE state variables (predator, prey) and the unknown parameter ``θ_1``: ``\mathbf{x}=[x,y,\alpha]
- we assume that the parameter is not changing in time ``\alpha(t_1)=\alpha(t_2)``
- this assumption extends the ODE by an additional state: 
```math
\dot\alpha = 0
```
forming a set of three differential equations: ``\dot x, \dot y, \dot \alpha``.

Observations are assumed to be a noisy transformation of the state. In our case, we would observe the prey variable:
```math
\begin{align}
\mathbf{y_t}&=h(\mathbf{x}) + σ_y e_t,  \,\,\, e_t \sim N(0,1) \\
h(\mathbf{x})&= \mathbf{x}_1
\end{align}
```

Assumption of the Gaussian uncertainty in the ODE as well as the noise is one of the easiest to solve, due to nice properties of the Gaussian distribution. Specifically, joint distribution of a marginal and conditional Gaussian distribution is a Gaussian distribution:
```math
\begin{align}
p(\mathbf{x},\mathbf{y})&=\mathcal{N}\left(\begin{bmatrix}\mu_{x}\\
\mu_{y}
\end{bmatrix},\begin{bmatrix}\Sigma_{xx} & \Sigma_{xy}\\
\Sigma_{yx} & \Sigma_{yy}
\end{bmatrix}\right)\\p(\mathbf{y})&=\mathcal{N}\left(\mu_{y},\Sigma_{yy}\right)\\p(\mathbf{x}|\mathbf{y})&=\mathcal{N}(\mu_{x}+\Sigma_{xy}\Sigma_{yy}^{-1}(\mathbf{y}-\mu_{y}),\Sigma_{xx}-\Sigma_{xy}\Sigma_{yy}^{-1}\Sigma_{yx})
\end{align}
```

![](mvgaussian.png)

- marginal distributions are unaffected by the correlation
- the correlation determines the reduction of uncertainty in the conditional case

We have uncertainty in all our unknowns ``p(\mathbf{x})`` in the form of quadrature points. We assume that the probability of observation of ``p(\mathbf{y}|\mathbf{x})`` has mean given by ``x`` and variance ``\sigma_y``.
Hence, the means can be obtained by empirical samples of the cubature points ``X_p`` and measurements corresponding to cubature points.
```math
\begin{align}
\mu_{x}&=\overline{X_{p}},& X_p &=[\mathbf{x}_1,\ldots \mathbf{x}_{2d}]\\
 mu_{y}&=\overline{Y_{p}}, & Y_p &=[h(\mathbf{x}_i),\ldots h(\mathbf{x}_{2d})]

\end{align}
```
e.g. if the measurements are only the ``x`` (prey variable) the ``y_i = x_{1,i}``.

The covariance matrices can be obtained by empirical samples:
```math
\begin{align}
\Sigma_{xx}&=\text{cov}(X_p,X_p)=\frac{1}{2d}\sum_{i=1}^{2d}(x{}_{i}-\mu_{x})^{T}(x_{i}-\mu_{x})\\
\Sigma_{yx}&=\text{cov}(Y_p,X_p)=\frac{1}{2d}\sum_{i=1}^{2d}(y{}_{i}-\mu_{y})^{T}(x_{i}-\mu_{x}),\\
\Sigma_{yy}&=\text{cov}(Y_p,Y_p)+\sigma_y^2=\frac{1}{2d}\sum_{i=1}^{2d}(y{}_{i}-\mu_{y})^{T}(y_{i}-\mu_{y})+\sigma_{y}^2,
\end{align}
```

The uncertainty reduction is then application of the conditional distribution using the obtained means and variances. A common trick is to define the Kalman gain:
```math
\begin{align}
K&=\Sigma_{xy}\Sigma_{yy}^{-1},\\
\mu_{x|y}&=\mu_{x}+K(\mathbf{y}-\mu_{y}),\\
\Sigma_{x|y}&=\Sigma_{xx}-K\Sigma_{yx},
\end{align}
```

The full algorithms is then as follows:
1. generate cubature points from their mean ``\mu_x`` and ``\Sigma_{xx}``
1. run propagation of the cubature points ``X_p`` through the ODE up to the time of the measurements,
2. compute their mean ``\mu_x`` and variance ``\Sigma_{xx}``,
3. for each cubature point compute the predicted measurement, ``Y_p``. Compute  mean ``\mu_y`` and covariance ``\Sigma_{yy}``
4. Compute the reduced uncertainty mean ``\mu_{x|y}`` and ``\Sigma_{x|y}``. These will be used to generate new cubature points in step 1.

Detailed implementation will follow in the lab.